{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb9b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings <- list(path_raw_data = '../input/')\n",
    "params <- list(cores=8)\n",
    "\n",
    "\n",
    "##### FUNCTIONS\n",
    "library(data.table)\n",
    "library(xgboost)\n",
    "library(parallel)\n",
    "\n",
    "read_raw_data <- function(fileID, filterID=NULL, train=F, test=F, \n",
    "                          n_batch=1, n_chunks=1, select=NULL, \n",
    "                          t_function=NULL, params=NULL, delete.unziped=F) {\n",
    "  # Libraries\n",
    "  library(data.table)\n",
    "  \n",
    "  # Check parameters\n",
    "  if (!fileID %in% c('numeric','date','categorical')) {\n",
    "    cat(\"\\nFileID ERROR\")\n",
    "    return()\n",
    "  }\n",
    "  if (!(train | test)) {\n",
    "    cat(\"\\nEmpty request\")\n",
    "    return()\n",
    "  }\n",
    "  \n",
    "  # Unzip files\n",
    "  train_filename <- paste0(settings$path_raw_data,\"train_\",fileID,\".csv\")\n",
    "  test_filename <- paste0(settings$path_raw_data,\"test_\",fileID,\".csv\")\n",
    "  if (train & !file.exists(train_filename)) unzip(paste0(train_filename,\".zip\"), exdir=settings$path_raw_data)\n",
    "  if (test & !file.exists(test_filename)) unzip(paste0(test_filename,\".zip\"), exdir=settings$path_raw_data)\n",
    "  \n",
    "  # Read header and set columns to read\n",
    "  if (train) {col_names <- fread(paste0(settings$path_raw_data,'train_',fileID,\".csv\"), nrows = 0L, skip = 0L)\n",
    "  } else {col_names <- fread(paste0(settings$path_raw_data,'test_',fileID,\".csv\"), nrows = 0L, skip = 0L)}\n",
    "  col_names <- colnames(col_names)\n",
    "  col_table <- data.table(idx = 1:length(col_names), name = col_names,\n",
    "                          do.call(rbind, sapply(col_names, function(x) strsplit(x,\"_\"))))\n",
    "  col_idx <- c(2:nrow(col_table))\n",
    "  if (!is.null(select)) {\n",
    "    idx_selected <- c(col_table$idx[col_table$name %in% select],\n",
    "                      col_table$idx[col_table$V1 %in% select],\n",
    "                      col_table$idx[col_table$V2 %in% select],\n",
    "                      col_table$idx[col_table$V3 %in% select])\n",
    "    idx_selected <- unique(idx_selected)\n",
    "    col_idx <- idx_selected[order(idx_selected)]\n",
    "  } else {\n",
    "    if (fileID == 'numeric' & train & test) {\n",
    "      col_idx <- col_idx[1:(length(col_idx)-1)] # remove Response\n",
    "    }\n",
    "  }\n",
    "  ifelse(n_batch>1, col_bat  <- cut(col_idx, n_batch, labels = c(1:n_batch)), col_bat  <- rep(1, length(col_idx)))\n",
    "  \n",
    "  # Set total rows\n",
    "  n_train <- 1183747\n",
    "  n_test <- 1183748\n",
    "  train_chunk_size <- floor(n_train / n_chunks)\n",
    "  test_chunk_size <- floor(n_test / n_chunks)\n",
    "  \n",
    "  # Set columns classes\n",
    "  if (fileID == 'categorical') {\n",
    "    colClasses <- c('numeric', rep('categorical', nrow(col_table)-1))\n",
    "    na.strings <- \"\"\n",
    "  } else {\n",
    "    colClasses <- 'numeric'\n",
    "    na.strings <- \"NA\"\n",
    "  }\n",
    "  \n",
    "  for (chunk_number in 0:(n_chunks-1)) {\n",
    "    train_skip <- train_chunk_size*chunk_number + 1\n",
    "    test_skip <- test_chunk_size*chunk_number + 1\n",
    "    if (chunk_number != (n_chunks-1)) {\n",
    "      train_nrows <- train_chunk_size\n",
    "      test_nrows <- test_chunk_size\n",
    "    } else {\n",
    "      train_nrows <- n_train - train_skip +1\n",
    "      test_nrows <- n_test - test_skip +1\n",
    "    }\n",
    "    \n",
    "    for(i in 1:n_batch) {\n",
    "      if (train) DT_train <- fread(paste0(settings$path_raw_data,\"train_\",fileID,\".csv\"),\n",
    "                                   showProgress = F, select = c(1, col_idx[col_bat == i]),\n",
    "                                   skip = train_skip, nrows = train_nrows,\n",
    "                                   colClasses = colClasses, na.strings = na.strings)\n",
    "      if (test) DT_test <- fread(paste0(settings$path_raw_data,\"test_\",fileID,\".csv\"),\n",
    "                                 showProgress = F, select = c(1, col_idx[col_bat == i]),\n",
    "                                 skip = test_skip, nrows = test_nrows,\n",
    "                                 colClasses = colClasses, na.strings = na.strings)\n",
    "      if (train & test) {\n",
    "        tmp_DT <- rbind(DT_train, DT_test)\n",
    "      } else {\n",
    "        ifelse(train, tmp_DT <- DT_train, tmp_DT <- DT_test)\n",
    "      }\n",
    "      \n",
    "      setnames(tmp_DT, col_names[c(1, col_idx[col_bat == i])])\n",
    "      setkey(tmp_DT, Id)\n",
    "      \n",
    "      if (!is.null(filterID)) {\n",
    "        tmp_DT <- tmp_DT[Id %in% filterID]\n",
    "      }\n",
    "      \n",
    "      if (!is.null(t_function)) {\n",
    "        tmp_DT <- t_function(tmp_DT, params)\n",
    "      }\n",
    "      \n",
    "      ifelse(i==1, DT <- tmp_DT, DT <- cbind(DT, tmp_DT[,2:ncol(tmp_DT), with=F]))\n",
    "      \n",
    "      # Clean memory\n",
    "      rm(tmp_DT)\n",
    "      if (train) rm(DT_train)\n",
    "      if (test) rm(DT_test)\n",
    "      gc()\n",
    "    }\n",
    "    \n",
    "    ifelse(chunk_number==0, complete_DT <- DT, complete_DT <- rbind(complete_DT, DT))\n",
    "    \n",
    "    # Clean memory\n",
    "    rm(DT); gc()\n",
    "    \n",
    "    \n",
    "  }\n",
    "  \n",
    "  # Delete files\n",
    "  if (train & delete.unziped) file.remove(paste0(settings$path_raw_data,\"train_\",fileID,\".csv\"))\n",
    "  if (test & delete.unziped) file.remove(paste0(settings$path_raw_data,\"test_\",fileID,\".csv\"))\n",
    "  \n",
    "  setkey(complete_DT, Id)\n",
    "  \n",
    "  return(complete_DT)\n",
    "}\n",
    "\n",
    "tf_date_structure <- function(DT, params=list('cores'=1)) {\n",
    "  \n",
    "  # Libraries\n",
    "  library(data.table)\n",
    "  library(parallel)\n",
    "  \n",
    "  mDT <- as.matrix(DT)\n",
    "  \n",
    "  feats <- mclapply(1:nrow(DT), function (i) {\n",
    "    \n",
    "    result <- mDT[i, 1]\n",
    "    result_names <- c('Id')\n",
    "    \n",
    "    fs <- 2:ncol(mDT)\n",
    "    \n",
    "    x <- mDT[i, fs]\n",
    "    result <- c(result, \n",
    "                ifelse(all(is.na(x)), NA, x[!is.na(x)][1]),\n",
    "                ifelse(all(is.na(x)), NA, min(x, na.rm=T)),\n",
    "                ifelse(all(is.na(x)), NA, rev(x[!is.na(x)])[1]),\n",
    "                ifelse(all(is.na(x)), NA, max(x, na.rm=T)),\n",
    "                ifelse(any(is.na(x)), length(unique(x))-1, length(unique(x))),\n",
    "                sum(is.na(x))\n",
    "    )\n",
    "    \n",
    "    result_names <- c(result_names, 'fst', 'min', 'lst', 'max', 'unique', 'NAs')\n",
    "    \n",
    "    names(result) <- result_names\n",
    "    \n",
    "    return(result)\n",
    "    \n",
    "  }, mc.cores=params['cores'], mc.preschedule = T)\n",
    "  feats <- do.call(rbind, feats)\n",
    "  feats <- as.data.table(feats)\n",
    "  setkey(feats, Id)\n",
    "  \n",
    "  return(feats)\n",
    "}\n",
    "\n",
    "tf_stations_mean <- function(DT, params=list('cores'=1)) {\n",
    "  \n",
    "  # Libraries\n",
    "  library(data.table)\n",
    "  library(parallel)\n",
    "  \n",
    "  c_names <- colnames(DT)\n",
    "  col_table <- data.table(idx = 1:length(c_names), name = c_names,\n",
    "                          do.call(rbind, sapply(c_names, function(x) strsplit(x,\"_\"))))\n",
    "  stations <- unique(col_table$V2[2:nrow(col_table)])\n",
    "  stat_list <- lapply(stations, function(x) col_table$idx[col_table$V2 == x])\n",
    "  mDT <- as.matrix(DT)\n",
    "  \n",
    "  feats <- mclapply(1:nrow(DT), function (i) {\n",
    "    \n",
    "    result <- mDT[i, 1]\n",
    "    result_names <- c('Id')\n",
    "    \n",
    "    for (s in 1:length(stat_list)) {\n",
    "      x <- mDT[i, stat_list[[s]] ]\n",
    "      result <- c(result,\n",
    "                  mean(x, na.rm = T)\n",
    "      )\n",
    "      result_names <- c(result_names, paste0(stations[s], c('.mean')))\n",
    "    }\n",
    "    \n",
    "    names(result) <- result_names\n",
    "    \n",
    "    return(result)\n",
    "    \n",
    "  }, mc.cores=params['cores'], mc.preschedule = T)\n",
    "  feats <- do.call(rbind, feats)\n",
    "  feats <- as.data.table(feats)\n",
    "  setkey(feats, Id)\n",
    "  \n",
    "  return(feats)\n",
    "}\n",
    "\n",
    "eval_mcc <- function(y_true, y_prob, result='mcc') {\n",
    "  DT <- data.table(y_true = y_true, y_prob = y_prob, key=\"y_prob\")\n",
    "  \n",
    "  nump <- sum(y_true)\n",
    "  numn <- length(y_true)- nump\n",
    "  \n",
    "  DT[, tn_v:= cumsum(y_true == 0)]\n",
    "  DT[, fp_v:= cumsum(y_true == 1)]\n",
    "  DT[, fn_v:= numn - tn_v]\n",
    "  DT[, tp_v:= nump - fp_v]\n",
    "  DT[, tp_v:= nump - fp_v]\n",
    "  DT[, mcc_v:= (tp_v * tn_v - fp_v * fn_v) / sqrt((tp_v + fp_v) * (tp_v + fn_v) * (tn_v + fp_v) * (tn_v + fn_v))]\n",
    "  DT[, mcc_v:= ifelse(!is.finite(mcc_v), 0, mcc_v)]\n",
    "  \n",
    "  ifelse(result=='mcc', return(max(DT[['mcc_v']])), return(DT[['y_prob']][which.max(DT[['mcc_v']])]))\n",
    "}\n",
    "\n",
    "find_prob <- function(y_prob, select) {\n",
    "  rev(sort(y_prob))[select+1]\n",
    "} \n",
    "\n",
    "\n",
    "##### MAIN\n",
    "\n",
    "## Read data\n",
    "print(\"Read data: DATE\")\n",
    "DTn <- read_raw_data(fileID=\"date\", train=T, test=T, n_chunks=18, \n",
    "                     t_function=tf_date_structure, params=params)\n",
    "\n",
    "print(\"Read data: DATE_L3\")\n",
    "DT3 <- read_raw_data(fileID=\"date\", train=T, test=T, n_chunks=7, select=\"L3\",\n",
    "                     t_function=tf_date_structure, params=params)\n",
    "setnames(DT3, c('Id', paste0('L3.',colnames(DT3)[2:ncol(DT3)])))\n",
    "\n",
    "#print(\"Read data: DATE_L3_mean\")\n",
    "#DTs <- read_raw_data(fileID=\"date\", train=T, test=T, n_chunks=3, select=\"L3\",\n",
    "#                     t_function=tf_stations_mean, params=params)\n",
    "#setnames(DTs, c('Id', paste0('S.',colnames(DTs)[2:ncol(DTs)])))\n",
    "\n",
    "print(\"Read data: TARGET\")\n",
    "target <- read_raw_data(fileID=\"numeric\", train=T, select=\"Response\")\n",
    "\n",
    "print(\"Read data: NUMERIC\")\n",
    "select <- c('L1_S24_F1846', 'L3_S32_F3850','L1_S24_F1695', 'L1_S24_F1632','L3_S33_F3855', 'L1_S24_F1604',\n",
    "            'L3_S29_F3407', 'L3_S33_F3865','L3_S38_F3952', 'L1_S24_F1723')\n",
    "tmpDT0 <- read_raw_data(fileID=\"numeric\", train=T, test=T, select=select)\n",
    "\n",
    "print(\"Read data: CATEGORICAL\")\n",
    "tmpDT1 <- read_raw_data(fileID=\"categorical\", train=T, test=T, select=c('S32'))\n",
    "\n",
    "print(\"Merging Data\")\n",
    "DT <- cbind(DTn, DT3, tmpDT0, tmpDT1) #, DTs)\n",
    "DT <- DT[, unique(colnames(DT)), with=F]\n",
    "DT <- merge(DT, target, all.x=T, by='Id')\n",
    "setcolorder(DT, c('Id', 'Response', setdiff(colnames(DT), c('Id', 'Response'))))\n",
    "setnames(DT, c('Id', 'Response'), c('ID', 'target'))\n",
    "setkey(DT, ID)\n",
    "\n",
    "rm(DTn, DT3, tmpDT0, tmpDT1, target) #, DTs)\n",
    "invisible(gc())\n",
    "\n",
    "\n",
    "## Feature Engineering (1)\n",
    "print(\"Generating Features\")\n",
    "tmpDT <- copy(DT[, c('ID', 'target','fst'), with=F])\n",
    "setkey(tmpDT, ID)\n",
    "tmpDT$fst[is.na(tmpDT$fst)] <- -tmpDT$ID[is.na(tmpDT$fst)] \n",
    "tmpDT[, next1:=as.numeric(fst == c(fst[2:nrow(DT)], 0))]\n",
    "tmpDT[, prev1:=as.numeric(fst == c(0, fst[2:nrow(DT) - 1]))]\n",
    "tmpDT[, nORp:=next1 + prev1]\n",
    "tmpDT[, P1:=nORp > 0]\n",
    "tmpDT[, ord:=Reduce(function(x,y){sum(c(x,y), na.rm=T)*y}, prev1, accumulate = T) + (nORp > 0)]\n",
    "tmpDT[, group:=cumsum(ord==1) * as.numeric(ord>0)]\n",
    "tmp <- tmpDT[, list(group_len=.N), by='group']\n",
    "tmpDT <- merge(tmpDT, tmp, by='group', all.x=T, sort = F)\n",
    "setkey(tmpDT, ID)\n",
    "\n",
    "\n",
    "## Feature Engineering (2)\n",
    "new_DT <- cbind(DT, tmpDT[,c('ord','P1','group_len','fst'),with=F])\n",
    "setkeyv(new_DT, c('ID'))\n",
    "new_DT[, time_L3:=L3.max-L3.min]\n",
    "new_DT[, time_dtL3:= time_L3 - c(NA, time_L3[2:nrow(DT)-1])]\n",
    "new_DT[, time_idtL3:= time_L3 - c(time_L3[2:nrow(DT)-0], NA)]\n",
    "new_DT[, NAs_dtL3:= L3.NAs - c(NA, L3.NAs[2:nrow(DT)-1])]\n",
    "new_DT[, NAs_idtL3:= L3.NAs - c(L3.NAs[2:nrow(DT)-0], NA)]\n",
    "\n",
    "\n",
    "## Select features\n",
    "LK_DT <- new_DT[,c('ID','target','P1', 'ord', 'group_len', 'fst',\n",
    "                   #'S.S32.mean', 'S.S33.mean', 'S.S38.mean',\n",
    "                   'L3.fst', 'L3.lst', 'time_dtL3', 'time_idtL3',\n",
    "                   'NAs_dtL3', 'NAs_idtL3',\n",
    "                   'L3_S32_F3851', 'L3_S32_F3853', 'L3_S32_F3854',\n",
    "                   'L1_S24_F1846', 'L3_S32_F3850', 'L1_S24_F1695', \n",
    "                   'L1_S24_F1632', 'L3_S33_F3855', 'L1_S24_F1604',\n",
    "                   'L3_S29_F3407', 'L3_S33_F3865', 'L3_S38_F3952', \n",
    "                   'L1_S24_F1723'),with=F]\n",
    "setkey(LK_DT, ID)\n",
    "## Categorical to nuemric\n",
    "LK_DT[, L3_S32_F3851:= as.numeric(factor(L3_S32_F3851, ordered = T))]\n",
    "LK_DT[, L3_S32_F3853:= as.numeric(factor(L3_S32_F3851, ordered = T))]\n",
    "LK_DT[, L3_S32_F3854:= as.numeric(factor(L3_S32_F3851, ordered = T))]\n",
    "## Add prev&next target\n",
    "LK_DT[, target_prev:= c(NA, target[1:(nrow(LK_DT)-1)])]\n",
    "LK_DT$target_prev[LK_DT$ord <= 1] <- NA\n",
    "LK_DT[, target_next:= c(target[2:(nrow(LK_DT))], NA)]\n",
    "LK_DT$target_next[c(LK_DT$ord[2:nrow(LK_DT)] < LK_DT$ord[1:(nrow(LK_DT)-1)], TRUE)] <- NA\n",
    "LK_DT$target_next[LK_DT$ord == 0] <- NA\n",
    "\n",
    "rm(DT, new_DT, tmp); invisible(gc())\n",
    "\n",
    "\n",
    "## Train & Predict\n",
    "print(\"Train & Predict\")\n",
    "dtrain <- xgb.DMatrix(data = as.matrix(LK_DT[!is.na(LK_DT$target), 3:ncol(LK_DT), with=F]), \n",
    "                      label = LK_DT$target[!is.na(LK_DT$target)], missing = NA)\n",
    "dtest  <- xgb.DMatrix(data = as.matrix(LK_DT[is.na(LK_DT$target), 3:ncol(LK_DT), with=F]), \n",
    "                      missing = NA)\n",
    "\n",
    "XGBparams <- list(nthread = 16, max_depth = 10, \n",
    "                  subsample = 0.9, colsample_bytree = 0.5, eta=0.1,\n",
    "                  objective   = \"reg:linear\", booster=\"gbtree\")\n",
    "set.seed(999)\n",
    "modelXGB <- xgb.train(data = dtrain, XGBparams, nrounds = 65, watchlist = list(train=dtrain))\n",
    "pred <- predict(modelXGB, dtest)\n",
    "prob <- find_prob(pred, 2700)\n",
    "\n",
    "\n",
    "## Submission\n",
    "submission <- read.csv(paste0(settings$path_raw_data, 'sample_submission.csv'))\n",
    "submission$Response <- as.numeric(pred > prob)\n",
    "write.csv(submission, \"submission.csv\", row.names = F)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
